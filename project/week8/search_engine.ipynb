{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfc14a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'jhe-koen-dev.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 1, Indexing\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m## https://github.com/jungyeul/korean-parallel-corpora\u001b[39;00m\n\u001b[0;32m     38\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjhe-koen-dev.en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 39\u001b[0m file_tokens_pairs \u001b[38;5;241m=\u001b[39m indexing(file_name)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 2. Input the query\u001b[39;00m\n\u001b[0;32m     42\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m영어 쿼리를 입력하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mindexing\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindexing\u001b[39m(file_name):\n\u001b[0;32m     10\u001b[0m     file_tokens_pairs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#전처리 된 문장을 저장할 리스트 생성\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreadlines()  \u001b[38;5;66;03m#파일 불러오기  \u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m     13\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m preprocess(line) \u001b[38;5;66;03m#각 줄을 preproecess 함수를 통해 전처리 한후 tokesns 에 저장\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'jhe-koen-dev.en'"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "#문장을 전처리 시키는 함수 생성\n",
    "def preprocess(sentence):\n",
    "    preprocessed_sentence = sentence.strip().split(\" \") #공백을 기준으로 단어로 분리 \n",
    "    return preprocessed_sentence\n",
    "\n",
    "#파일에서 문장을 읽어온 후 전처리 해서 저장시키는 함수 생성\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = [] #전처리 된 문장을 저장할 리스트 생성\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines()  #파일 불러오기  \n",
    "    for line in lines:\n",
    "        tokens = preprocess(line) #각 줄을 preproecess 함수를 통해 전처리 한후 tokesns 에 저장\n",
    "        file_tokens_pairs.append(tokens) #  fill_tokens_pairs 리스트에 tokens 값 추가\n",
    "    return file_tokens_pairs\n",
    "\n",
    "# 쿼리와 문장의 유사도를 계산하는 함수 \n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {} #문장 인덱스와 유사도를 저장할 수 있는 딕셔너리 생성\n",
    "    for i in range(len(preprocessed_sentences)):        \n",
    "        # 시작: 대소문자 구분 없는 토큰 셋을 만들기 위한 코드\n",
    "        sentence = preprocessed_sentences[i] #파일에서 읽은 전처리 문장\n",
    "        query_str = ' '.join(preprocessed_query).lower() #사용자에게 입력받은 쿼리를 공백으로 연결 후 소문자로 변환\n",
    "        sentence_str = ' '.join(sentence).lower() #파일에서 읽은 전처리 문장을 공백으로 연결하고 소문자로 변환\n",
    "        preprocessed_query = set(preprocess(query_str)) #쿼리를 다시 전처리 후 토큰의 집합을 생성\n",
    "        preprocessed_sentence = preprocess(sentence_str)  #문장을 다시 전처리        \n",
    "        # 끝: 대소문자 구분 없는 토큰 셋을 만들기 위한 코드               \n",
    "        \n",
    "        file_token_set = set(preprocessed_sentence) #파일에서 읽은 문장의 토큰에 집합\n",
    "        all_tokens = preprocessed_query | file_token_set #쿼리와 문장의 모든 토큰의 집합\n",
    "        same_tokens = preprocessed_query & file_token_set # 쿼리와 문장에서 공통된 토큰 집합\n",
    "        similarity = len(same_tokens) / len(all_tokens) #유사도 계산\n",
    "        score_dict[i] = similarity #문장의 인덱스와 유사도를 딕셔너리에 저장\n",
    "    return score_dict #딕셔너리 반환\n",
    "\n",
    "# 1, Indexing\n",
    "## https://github.com/jungyeul/korean-parallel-corpora\n",
    "file_name = \"jhe-koen-dev.en\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요.\")\n",
    "preprocessed_query = preprocess(query)\n",
    "query_token_set = set(preprocessed_query)\n",
    "\n",
    "# 3. Calculate similarities based on a same token set\n",
    "score_dict = calc_similarity(query_token_set, file_tokens_pairs)\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. Print the result\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\")\n",
    "    rank = 1\n",
    "    for i, score  in sorted_score_list:\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10:\n",
    "            break\n",
    "        rank = rank + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75f217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
